<html>
    <link href="https://cdn.jsdelivr.net/npm/bootstrap@5.2.1/dist/css/bootstrap.min.css" rel="stylesheet"
    integrity="sha384-iYQeCzEYFbKjA/T2uDLTpkwGzCiq6soy8tYaI1GyVh/UjpbCx/TYkiZhlZB6+fzT" crossorigin="anonymous" />
    <script src="dist/ort.all.min.js"> </script>

<!--
    <script src="https://cdn.jsdelivr.net/npm/onnxruntime-web@1.17.0-dev.20231118-9364c05170/dist/ort.webgpu.min.js"> </script>
    <script src="https://cdn.jsdelivr.net/npm/onnxruntime-web@1.16.3/dist/ort.webgpu.min.js"> </script>
    <script src="https://cdn.jsdelivr.net/npm/onnxruntime-web/dist/ort.webgpu.min.js"></script>
    <script src="dist/ort.min.js"> </script>
    <script src="dist/ort.js"> </script>
    <script src="dist/ort.webgpu.min.js"> </script>
-->

<head>
    <title>ort-web perf</title>
</head>
<style>
    .sidebar {
        margin: 0;
        padding: 1;
        width: 200px;
        background-color: #f1f1f1;
        position: fixed;
        height: 100%;
        overflow: auto;
        overflow-y: scroll;
        scrollbar-width: 8px;
    }

    .sidebar a {
        display: block;
        color: black;
        text-decoration: none;
        overflow: hidden;
    }

    .sidebar a.active {
        background-color: #04AA6D;
        color: white;
    }

    .sidebar a:hover:not(.active) {
        background-color: #555;
        color: white;
    }

    .content {
        margin-left: 220px;
    }
</style>

<body>
    <div class="containerx" style="padding-left: 10px;">
        <h1>ort-web perf</h1>
        <div id="nav" class="sidebar d-grid gap-5 d-md-block">
        </div>
        <div class="content">
            <div class="d-grid gap-5 d-md-block">
                <button class="btn btn-primary" type="button" onclick="bench();">bench</button>
            </div>
            <div class="d-grid gap-5 d-md-block">
                <div class="progress" style="width: 50%; margin-top: 10; display: none;">
                    <div id="progress" class="progress-bar progress-bar-striped" role="progressbar" style="width: 10%"
                        aria-valuenow="0" aria-valuemin="0" aria-valuemax="100" sam></div>
                </div>
            </div>
            <p class="text-lg-start">
            <div id="results" style="font: 1em consolas;"></div>
            </p>
            <div id="download"></div>

            <p class="text-lg-start">
            <div id="status" style="font: 1em consolas;"></div>
            </p>
        </div>
    </div>
</body>

<script src="./ort-perf-models.js"> </script>

<script>
    function populateNav(config) {
        const nav = document.getElementById("nav");
        for (let i = 0; i < models.length; i++) {
            const model = models[i];
            if (model.e === undefined) {
                model.e = "default";
            }
            if (model.o === undefined) {
                model.o = "";
            }
            if (model.e != config.filter) {
                continue;
            }
            const a = document.createElement("a");
            a.href = `?filter=${config.filter}&provider=${config.provider}&name=${model.n}&gen=${model.g}&model=${model.m}${model.o}`;
            a.innerText = model.n;
            if (model.n == config.name) {
                a.className = "active";
            }
            nav.appendChild(a);
        }

        if (config.model === undefined && config.name !== undefined) {
            for (let i = 0; i < models.length; i++) {
                const model = models[i];
                if (model.n == config.name && model.e == config.filter) {
                    config.model = model.m;
                    config.gen = model.g;
                    break;
                }
            }
            if (config.model === undefined) {
                throw new Error(`${config.filter} / ${config.name} not defined`);
            }
        }
    }

    function log(i) {
        console.log(i);
        document.getElementById('status').innerText += `\n[${performance.now().toFixed(3)}] ` + i;
    }

    function sleep(ms) {
        return new Promise(resolve => setTimeout(resolve, ms));
    }

    function getConfig() {
        const query = window.location.search.substring(1);
        var config = {
            model: undefined,
            name: undefined,
            filter: "default",
            provider: "webgpu",
            device: "cpu",
            threads: "1",
            profiler: "0",
            gen: "img224",
            verbose: "0",
            min_query_count: "30",
            min_query_time: "10",
            seqlen: "128",
            enc_seqlen: "128",
            io_binding: "0",
            static_shapes: "0",
            prevent_fallback: "0",
            preferred_layout: "NHWC",
            go: 0,
            csv: 0,
            download: 0,
            validate: 0,
            name: undefined
        };
        let vars = query.split("&");
        for (var i = 0; i < vars.length; i++) {
            let pair = vars[i].split("=");
            if (pair[0] in config) {
                config[pair[0]] = decodeURIComponent(pair[1]);
            } else if (pair[0].length > 0) {
                throw new Error("unknown argument: " + pair[0]);
            }
        }
        config.threads = parseInt(config.threads);
        config.verbose = parseInt(config.verbose);
        config.seqlen = parseInt(config.seqlen);
        config.enc_seqlen = parseInt(config.enc_seqlen);
        config.io_binding = (config.io_binding == "1");
        config.static_shapes = (config.static_shapes == "1");
        config.go = parseInt(config.go);
        config.profiler = parseInt(config.profiler);
        config.csv = parseInt(config.csv);
        config.download = parseInt(config.download);
        config.validate = parseInt(config.validate);
        config.min_query_time = parseFloat(config.min_query_time) * 1000;
        config.min_query_count = parseInt(config.min_query_count);
        return config;
    }

    function logPercentiles(config, data) {
        const fp = 2;
        let result = {};
        const calculatePercentile = (percentile, numbers) => {
            const pos = Math.ceil(percentile / 100.0 * numbers.length) - 1;
            return numbers[pos];
        };

        data.sort(function (a, b) { return a - b }); // increasing.
        const sum = data.reduce((a, b) => a + b);
        result.avg = (sum / data.length).toFixed(fp);
        result.count = data.length;
        result.pass = 1;
        result.mem = 0;
        result.count = data.length;
        result.threads = config.threads;
        result.name = config.name;
        result.provider = config.provider;
        result.min = data[0].toFixed(fp);
        result.max = data[data.length - 1].toFixed(fp);
        result.p50 = calculatePercentile(50, data).toFixed(fp);
        result.p95 = calculatePercentile(95, data).toFixed(fp);
        result.p99 = calculatePercentile(99, data).toFixed(fp);
        return result;
    }

    async function fetchAndCache(url) {
        try {
            const cache = await caches.open("onnx");
            let cachedResponse = await cache.match(url);
            if (cachedResponse == undefined) {
                await cache.add(url);
                cachedResponse = await cache.match(url);
                log(`${url} (network)`);
            } else {
                log(`${url} (cached)`);
            }
            const data = await cachedResponse.arrayBuffer();
            return data;
        } catch (error) {
            log(`${url} (network)`);
            return await fetch(url).then(response => response.arrayBuffer());
        }
    }

    function fillTensor(shape, dtype, val = 1) {
        let size = 1;
        shape.forEach(element => {
            size *= element;
        });
        switch (dtype) {
            case "float32":
                return new ort.Tensor(Float32Array.from({ length: size }, () => val), shape);
            case "float16":
                return new ort.Tensor("float16", Uint16Array.from({ length: size }, () => val), shape);
            case "int32":
                return new ort.Tensor(Int32Array.from({ length: size }, () => val), shape);
            case "int64":
                if (typeof (val) != BigInt) {
                    val = BigInt(val)
                }
                return new ort.Tensor(BigInt64Array.from({ length: size }, () => val), shape);
        }
        throw new Error(`Input tensor type ${dtype} is not supported`);
    }

    function randomTensor(shape, dtype) {
        let size = 1;
        shape.forEach(element => {
            if (element > 1) {
                size *= element;
            }
        });
        switch (dtype) {
            case "float32":
                return new ort.Tensor(Float32Array.from({ length: size }, () => Math.random()), shape);
        }
        throw new Error(`Input tensor type ${dtype} is not supported`);
    }

    function rampTensor(shape, dtype) {
        let size = 1;
        shape.forEach(element => {
            if (element > 1) {
                size *= element;
            }
        });
        switch (dtype) {
            case "float32":
                return new ort.Tensor(Float32Array.from({ length: size }, (_, i) => i), shape);
            case "int32":
                return new ort.Tensor(Int32Array.from({ length: size }, (_, i) => i), shape);
            case "int64":
                return new ort.Tensor(BigInt64Array.from({ length: size }, (_, i) => i), shape);
        }
        throw new Error(`Input tensor type ${dtype} is not supported`);
    }

    function dump_feed(feed) {
        for (const [name, t] of Object.entries(feed)) {
            log(`${name}: ${t.type} ${t.dims}`);
        }
    }

    function make_inputs(gen, inputNames, config) {
        const seqlen = config.seqlen;
        const enc_seqlen = config.enc_seqlen;
        const feed = {};
        const name = inputNames[0];
        if (gen == "sd-text-encoder") {
            const ids = [
                49406, 320, 25602, 2000, 539, 320, 1794, 1773, 7100, 3309, 550, 29616, 5175, 14222, 23116, 269, 49407,
                0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
                0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
            ];
            feed["input_ids"] = new ort.Tensor("int32", new Int32Array(ids), [1, 77]);
            return feed;
        }
        if (gen == "sd-turbo-unet") {
            feed["sample"] = fillTensor([1, 4, 64, 64], "float32");
            feed["timestep"] = fillTensor([1], "int64", 999n);
            feed["encoder_hidden_states"] = fillTensor([1, 77, 1024], "float32");
            return feed;
        }
        if (gen == "sd-turbo-vae") {
            feed["latent_sample"] = fillTensor([1, 4, 64, 64], "float32", 9);
            return feed;
        }
        if (gen == "sd-unet") {
            feed["sample"] = fillTensor([1, 4, 64, 64], "float16");
            feed["timestep"] = fillTensor([1], "int64", 999n);
            feed["encoder_hidden_states"] = fillTensor([1, 77, 1024], "float16");
            return feed;
        }
        if (gen == "sd-vae") {
            feed["latent_sample"] = fillTensor([1, 4, 64, 64], "float16");
            return feed;
        }
        if (gen == "vit") {
            for (var k in inputNames) {
                const v = inputNames[k];
                if (v.includes("_values")) {
                    feed[v] = rampTensor([1, 3, 224, 224], "float32");
                } else if (v == "attention_mask") {
                    feed[v] = fillTensor([1, seqlen], "int64", 1n);
                } else {
                    feed[v] = fillTensor([1, seqlen], "int64", 49407n);
                }
            }
            return feed;
        }
        if (gen == "clip") {
            feed["input_ids"] = fillTensor([1, 77], "int64", 49407n);
            feed["pixel_values"] = fillTensor([1, 3, 224, 224], "float32", 99);
            feed["attention_mask"] = fillTensor([1, 77], "int64", 1n);
            return feed;
        }
        if (gen == "clipseg") {
            feed["input_ids"] = fillTensor([1, 77], "int64", 99n);
            feed["pixel_values"] = fillTensor([1, 3, 352, 352], "float32", 99);
            feed["attention_mask"] = fillTensor([1, 77], "int64", 1n);
            return feed;
        }
        if (gen == "detr") {
            feed["pixel_values"] = fillTensor([1, 3, 224, 224], "float32", 99);
            feed["pixel_mask"] = fillTensor([1, 64, 64], "int64", 1n);
            return feed;
        }
        if (gen == "detr-800") {
            feed["pixel_values"] = fillTensor([1, 3, 800, 800], "float32", 99);
            feed["pixel_mask"] = fillTensor([1, 64, 64], "int64", 1n);
            return feed;
        }
        if (gen == "mobilevit") {
            feed["pixel_values"] = fillTensor([1, 3, 224, 224], "float32", 99);
            return feed;
        }
        if (gen == "wav2vec") {
            feed["input_values"] = fillTensor([1, 512], "float32");
            return feed;
        }
        if (gen == "whisper-encoder") {
            feed["input_features"] = fillTensor([1, 80, 3000], "float32");
            return feed;
        }
        if (gen == "whisper-decoder") {
            feed["input_ids"] = fillTensor([1, seqlen], "int64", 1n);
            feed["encoder_hidden_states"] = fillTensor([1, 1500, 384], "float32");
            // past_key_values.0.encoder.value[FLOAT, batch_sizex6xencoder_sequence_length_outx64]
            // past_key_values.1.decoder.key[FLOAT, batch_sizex6xpast_decoder_sequence_lengthx64]
            const decoder_shape = [1, 6, seqlen, 64];
            const encoder_shape = [1, 6, 1500, 64];
            for (var k in inputNames) {
                const v = inputNames[k];
                if (v.startsWith("past_key_values.")) {
                    if (v.includes("decoder")) {
                        feed[v] = fillTensor(decoder_shape, "float32", 1);
                    } else if (v.includes("encoder")) {
                        feed[v] = fillTensor(encoder_shape, "float32", 1);
                    }
                }
            }
            feed['use_cache_branch'] = new ort.Tensor("bool", [0], [1]);
            return feed;
        }
        if (gen == "distil-whisper-decoder") {
            feed["input_ids"] = fillTensor([1, seqlen], "int64", 1n);
            feed["encoder_hidden_states"] = fillTensor([1, 1500, 768], "float32");
            const decoder_shape = [1, 12, seqlen, 64];
            const encoder_shape = [1, 12, 1500, 64];
            for (var k in inputNames) {
                const v = inputNames[k];
                if (v.startsWith("past_key_values.")) {
                    if (v.includes("decoder")) {
                        feed[v] = fillTensor(decoder_shape, "float32", 1);
                    } else if (v.includes("encoder")) {
                        feed[v] = fillTensor(encoder_shape, "float32", 1);
                    }
                }
            }
            feed['use_cache_branch'] = new ort.Tensor("bool", [0], [1]);
            return feed;
        }
        if (gen == "img512") {
            feed[name] = rampTensor([1, 3, 512, 512], "float32");
            return feed;
        }
        if (gen == "img224-fp16") {
            feed[name] = fillTensor([1, 3, 224, 224], "float16");
            return feed;
        }
        if (gen == "img224") {
            feed[name] = rampTensor([1, 3, 224, 224], "float32");
            return feed;
        }
        if (gen == "img4x224x224") {
            feed[name] = fillTensor([1, 4, 224, 224], "float32", 0.5);
            return feed;
        }
        if (gen == "img640x480") {
            feed[name] = randomTensor([1, 3, 640, 480], "float32");
            return feed;
        }
        if (gen == "img640x640") {
            feed[name] = randomTensor([1, 3, 640, 640], "float32");
            return feed;
        }
        if (gen == "img512x512") {
            feed[name] = randomTensor([1, 3, 512, 512], "float32");
            return feed;
        }
        if (gen == "img224nhwc") {
            feed[name] = rampTensor([1, 224, 224], "float32");
            return feed;
        }
        if (gen == "bert" || gen == "bert64") {
            const dtype = (gen == "bert") ? "int32" : "int64";
            const val = (gen == "bert") ? 99 : 99n;
            const one = (gen == "bert") ? 1 : 1n;

            for (var k in inputNames) {
                const v = inputNames[k];
                if (v === "input_ids") {
                    feed[v] = fillTensor([1, seqlen], dtype, val);
                }
                if (v === "input_mask" || v === "attention_mask") {
                    feed[v] = fillTensor([1, seqlen], dtype, one);
                }
                if (v === "token_type_ids" || v == "segment_ids") {
                    feed[v] = fillTensor([1, seqlen], dtype, one);
                }
            }
            return feed;
        }
        if (gen == "llm-decoder") {
            // const ids = [40n, 2883n, 6155n, 351n, 616n, 13779n, 3290n, 11n];
            for (var k in inputNames) {
                const v = inputNames[k];
                if (v.startsWith("past_key_values")) {
                    feed[v] = fillTensor([1, 12, 0, 64], "float32", .5);
                }
            }
            feed['use_cache_branch'] = new ort.Tensor("bool", [false], [1]);
            feed["input_ids"] = fillTensor([1, seqlen], "int64", 40n);
            feed["attention_mask"] = fillTensor([1, seqlen], "int64", 1n);
            return feed;
        }
        if (gen == "starcoder") {
            for (var k in inputNames) {
                const v = inputNames[k];
                if (v.startsWith("past_key_values")) {
                    feed[v] = fillTensor([1, seqlen, 128], "float32", 1.);
                }
            }
            feed['use_cache_branch'] = new ort.Tensor("bool", [0], [1]);
            feed["input_ids"] = fillTensor([1, seqlen], "int64", 99n);
            feed["attention_mask"] = fillTensor([1, seqlen], "int64", 1n);
            return feed;
        }
        if (gen == "bart-large" || gen == "bart-large-12") {
            const kvdim = (gen == "bart-large") ? 16 : 12;
            const hiddendim = (gen == "bart-large") ? 1024 : 768;
            for (var k in inputNames) {
                const v = inputNames[k];
                if (v.startsWith("past_key_values")) {
                    feed[v] = fillTensor([1, kvdim, seqlen, 64], "float32", 1.);
                }
                if (v.startsWith("encoder_attention_mask")) {
                    feed["encoder_attention_mask"] = fillTensor([1, enc_seqlen], "int64", 1n);
                }
            }
            feed['use_cache_branch'] = new ort.Tensor("bool", [0], [1]);
            feed["input_ids"] = fillTensor([1, seqlen], "int64", 99n);
            feed["encoder_hidden_states"] = fillTensor([1, enc_seqlen, hiddendim], "float32", 1);
            return feed;
        }
        if (gen == "bart-cnn") {
            for (var k in inputNames) {
                const v = inputNames[k];
                if (v.startsWith("past_key_values")) {
                    feed[v] = fillTensor([1, 16, seqlen, 64], "float32", 1.);
                }
                if (v == "encoder_attention_mask") {
                    feed["encoder_attention_mask"] = fillTensor([1, enc_seqlen], "int64", 1n);
                }
            }
            feed['use_cache_branch'] = new ort.Tensor("bool", [0], [1]);
            feed["input_ids"] = fillTensor([1, seqlen], "int64", 99n);
            feed["encoder_hidden_states"] = fillTensor([1, seqlen, 1024], "float32", 1);
            return feed;
        }
        if (gen == "vae-decoder") {
            feed[name] = fillTensor([1, 4, 64, 64], "float32", 1);
            return feed;
        }
        if (gen == "sam-decoder") {
            feed["image_embeddings"] = fillTensor([1, 256, 64, 64], "float32", 0.5);
            feed["point_coords"] = new ort.Tensor(new Float32Array([327.1111, 426.875, 241.77777, 341.5, 398.22223, 498.02084]), [1, 3, 2]);
            feed["point_labels"] = new ort.Tensor(new Float32Array([0., 2., 3.]), [1, 3]);
            feed["mask_input"] = fillTensor([1, 1, 256, 256], "float32", 0.);
            feed["has_mask_input"] = fillTensor([1], "float32", 1.);
            if (inputNames.includes("orig_im_size")) {
                feed["orig_im_size"] = new ort.Tensor(new Float32Array([512., 512.]), [2]);
            }
            return feed;
        }
        if (gen == "sam-encoder") {
            feed["input_image"] = fillTensor([1024, 1024, 3], "float32", 1.);
            return feed;
        }
        if (gen == "sam-mobile-encoder") {
            feed["input_image"] = fillTensor([1, 3, 1024, 1024], "float32", 1.);
            return feed;
        }
        if (gen == "t5-encoder") {
            feed['input_ids'] = fillTensor([1, seqlen], "int64", 99n);
            feed['attention_mask'] = fillTensor([1, seqlen], "int64", 1n);
            return feed;
        }
        if (["t5-decoder", "flan-t5-decoder", "t5-decoder-i32"].includes(gen)) {
            let type = "int64";
            if (gen.includes("-i32")) {
                gen = gen.replace("-i32", "")
                type = "int32"
            }
            feed['input_ids'] = fillTensor([1, seqlen], type, 99);
            feed['encoder_hidden_states'] = fillTensor([1, enc_seqlen, 512], "float32", 1);
            const encoder_shape = (gen == "t5-decoder") ? [1, 8, enc_seqlen, 64] : [1, 6, enc_seqlen, 64];
            const decoder_shape = (gen == "t5-decoder") ? [1, 8, 0, 64] : [1, 6, 0, 64];
            for (var k in inputNames) {
                const v = inputNames[k];
                if (v.startsWith("past_key_values.")) {
                    if (v.includes("decoder")) {
                        feed[v] = fillTensor(decoder_shape, "float32", 1);
                    } else if (v.includes("encoder")) {
                        feed[v] = fillTensor(encoder_shape, "float32", 1);
                    }
                }
                if (v == "encoder_attention_mask") {
                    feed['encoder_attention_mask'] = fillTensor([1, enc_seqlen], type, 1);
                }
            }
            feed['use_cache_branch'] = new ort.Tensor("bool", [false], [1]);
            return feed;
        }
		if (gen == "NbitMatMul") {
		feed['X'] = fillTensor([512, 512], "float32", 0);
		return feed;
		}
		if (gen == "phi2") {
            const tokens = [24446n, 502n, 546n, 262n, 46371n, 286n, 257n, 2588n, 392n, 7496n];
            feed['input_ids'] = new ort.Tensor(new BigInt64Array(tokens), [1, tokens.length]);
            feed['attention_mask'] = fillTensor([1, 1], "int64", 1n);
            feed['position_ids'] = fillTensor([1, tokens.length], "int64", 1n);
            const decoder_shape = [1, 32, 0, 80];
            for (var i = 0; i < 32; i++) {
                feed['past_key_values.' + i + '.key'] = fillTensor(decoder_shape, 'float16', 1);
                feed['past_key_values.' + i + '.value'] = fillTensor(decoder_shape, 'float16', 1);
            }
            return feed;
        }
        throw new Error(`unknown gendata ${gen}`);
    }

    function create_download_link(cons_cout) {
        let link = document.getElementById('download').childNodes[0];
        if (link === undefined) {
            link = document.createElement("a", "download-link");
            link.download = "profiler.log";
            link.innerText = "Download";
            document.getElementById('download').appendChild(link);
        }
        const base64 = btoa(cons_out.join('\n'));
        link.href = `data:application/json;base64,${base64}`;
    }

    const type_to_func = {
        "float32": Float32Array,
        "float16": Uint16Array,
        "int32": Int32Array,
        "BigInt64Array": BigInt64Array,
        "int64": BigInt64Array,
    };

    function clone(x) {
        if (ort.env.wasm.proxy) {
            let feed = {};
            for (const [key, value] of Object.entries(x)) {
                let func = type_to_func[value.type];
                feed[key] = new ort.Tensor(value.type, func.from(value.data), value.dims);
            }
            return feed;
        } else {
            return x;
        }
    }

    function copy_kv_caches(feed, outputs) {
        for (const [name, t] of Object.entries(outputs)) {
            if (name.startsWith('present')) {
                let newName = name.replace('present', 'past_key_values');
                if (t.dims[0] == 0) {
                    // Optimization introduced by optimum to reuse past key values: keep previous value.
                    t.dispose();
                } else {
                    // this dispose is critical since we own that gpu-buffer
                    feed[newName].dispose();
                    feed[newName] = t;
                }
            }
        }
    }

    function webgpu_tensor_from_tensor(t) {
        const device = ort.env.webgpu.device;
        const gpubuf = device.createBuffer({ mappedAtCreation: true, size: t.data.byteLength, usage: GPUBufferUsage.STORAGE });
        const arr = gpubuf.getMappedRange();
        new Uint8Array(arr).set(t.data);
        gpubuf.unmap();
        return ort.Tensor.fromGpuBuffer(gpubuf, {type: t.type, dims: t.dims});
    }

    function apply_io_binding(sess, opt, feed) {
        // encoder_hidden_states
        opt.preferredOutputLocation = {};
        const kv_names = sess.outputNames.filter(n => n.includes('present') || n.includes('hidden_state'));
        kv_names.forEach(name => {
            opt.preferredOutputLocation[`${name}`] = "gpu-buffer";
        });
        for (const [name, t] of Object.entries(feed)) {
            if (name.includes('encoder_hidden_states')) {
                feed[name] = webgpu_tensor_from_tensor(t);
                t.dispose();
            }
        };
    }

    function compareArrays(a, b, relError = 0.1, absError = 1) {
        // Check if the arrays have the same length
        let res = [];
        if (a.length !== b.length) {
            return false;
        }
        for (let i = 0; i < a.length; i++) {
            // Get the absolute difference between the corresponding elements
            let v1 = a[i];
            let v2 = b[i];
            if (typeof v1 == "bigint") {
                v1 = parseFloat(v1.toString())
            }
            if (typeof v2 == "bigint") {
                v2 = parseFloat(v2.toString())
            }
            const diff = Math.abs(v1 - v2);
            // Get the maximum absolute value of the corresponding elements
            let max = Math.max(Math.abs(v1), Math.abs(v2));
            // Check if the difference is greater than the absolute error
            if (diff > absError) {
                res.push([i, v1, v2]);
            } else if (diff > relError * max) {
                res.push([i, v1, v2]);
            }
        }
        return res;
    }

    const rows = [
        "name", "provider", "pass", "threads", "avg", "min", "max", "p50", "p95", "p99",
        "count", "mem", "tag", "platform", "fist_run", "load"
    ];

    var cons_out = [];

    const progress = document.getElementById('progress');
    const config = getConfig();

    ort.env.wasm.numThreads = config.threads;
    ort.env.wasm.simd = true;
    ort.env.wasm.proxy = (config.provider == "webnn");

    populateNav(config);


    switch (config.provider) {
        case "webgpu":
            if (!("gpu" in navigator)) {
                throw new Error("webgpu is NOT supported");
            }
            break;
        case "webnn":
            if (!("ml" in navigator)) {
                throw new Error("webnn is NOT supported");
            }
            break;
    }

    if (config.download) {
        console.log = function (message) {
            cons_out.push(message);
        };
    }

    async function bench() {
        try {
            document.getElementById('status').innerText = "";
            const use_proxy = ort.env.wasm.proxy;

            const opt = {
                executionProviders: ["wasm"],
                enableProfiling: config.profiler > 0,
                enableMemPattern: false,
                enableCpuMemArena: false,
                extra: {
                    session: {
                        disable_prepacking: "1",
                        use_device_allocator_for_initializers: "1",
                        use_ort_model_bytes_directly: "1",
                        use_ort_model_bytes_for_initializers: "1",
                        disable_cpu_ep_fallback: config.prevent_fallback,
                    }
                },
                freeDimensionOverrides: { batch_size: 1, },
            };

            if (config.verbose) {
                opt.logSeverityLevel = 0;
                opt.logVerbosityLevel = 0;
                ort.env.debug = true;
                ort.env.logLevel = "verbose";
            }

            switch (config.provider) {
                case "webnn":
                    opt.executionProviders = [{
                        name: "webnn",
                        deviceType: config.device,
                        powerPreference: 'default',
                        numThreads: config.threads,
                    }];
                    break;
                case "webgpu":
                    opt.executionProviders = [{
                        name: "webgpu",
                        preferredLayout: config.preferred_layout
                    }];
                    if (config.profiler) {
                        ort.env.webgpu.profilingMode = 'default';
                    }
                    break;
            }

            // burn in static shapes
            if (config.name.includes("sd-unet-fp16")) {
                opt.freeDimensionOverrides = {
                    num_channels: 4,
                    height: 64,
                    width: 64,
                    steps: 1,
                    sequence_length: 77,
                }
            }
            if (config.name.includes("sd-vae-fp32")) {
                opt.freeDimensionOverrides = {
                    channels: 4,
                    height: 64,
                    width: 64,
                    batch: 1,
                }
            }

            // opt.optimizedModelFilePath = 'opt.onnx';
            // opt.graphOptimizationLevel = "disabled";

            log(`loading... ${config.name},  ${config.provider}`);
            const model_bytes = await fetchAndCache("models/" + config.model);
            log(`model size ${Math.round(model_bytes.byteLength / 1024 / 1024)} MB`);

            const load_start = performance.now();
            var sess = await ort.InferenceSession.create(model_bytes, opt);
            const load = performance.now() - load_start;
            const feed = make_inputs(config.gen, sess.inputNames, config);
            const durations = [];

            if (config.validate) {
                let vsess = await ort.InferenceSession.create(model_bytes, { executionProviders: ["wasm"] });
                const valid_outputs = await vsess.run(clone(feed));
                vsess.release();
                const outputs = await sess.run(clone(feed));
                for (const [name, t] of Object.entries(valid_outputs)) {
                    const res = compareArrays(valid_outputs[name].data, outputs[name].data);
                    if (res.length > 0) {
                        log(`${name}, ERROR`);
                        log(`${name}, ${res.length} of ${valid_outputs[name].data.length} or ${res.length * 100 / valid_outputs[name].data.length}% are wrong`);
                        for (var i = 0; i < Math.min(5, res.length); i++) {
                            log(`${name}, ${res[i]}`);
                        }
                    } else {
                        log(`${name}, OK`);
                    }
                }
                return;
            }

            if (config.provider == "webgpu" && config.io_binding) {
                apply_io_binding(sess, opt, feed);
                sess.release();
                sess = await ort.InferenceSession.create(model_bytes, opt);
            }

            if (config.profiler) {
                log("profiling...");
                for (var i = 0; i < 10; i++) {
                    const start = performance.now();
                    const outputs = await sess.run(clone(feed));
                    durations.push(performance.now() - start);
                    if (i == 0 && feed["use_cache_branch"] !== undefined) {
                        if (config.gen != "llm-decoder" || config.seqlen == 1) {
                            copy_kv_caches(feed, outputs)
                            log(`using use_cache_branch, setting to 1`);
                            feed['use_cache_branch'] = new ort.Tensor("bool", [true], [1]);
                        }
                    } else if (config.io_binding) {
                        copy_kv_caches(feed, outputs);
                    }
                }
                await sess.endProfiling();
                log("profiling done @@1.");
                const r = logPercentiles(config, durations);
                const result = `${r.name}/${r.provider}/${r.threads} avg: ${r.avg}, min: ${r.min}, max: ${r.max}, p50: ${r.p50}, p95: ${r.p95}, p99: ${r.p99}, count=${r.count}`;
                log(result + " @@1");
                sess.release();
                // ort.env.webgpu.backend.gpuDataManager.dump(r.name);
                if (config.download) {
                    create_download_link(cons_out);
                }
                return;
            }

            log("warmup...");
            await sleep(200);
            let fist_run = 0;
            {
                const start = performance.now();
                let outputs = await sess.run(clone(feed));
                fist_run = performance.now() - start;
                log(`1strun: ${fist_run.toFixed(2)}ms, load: ${load.toFixed(2)}ms`);
                await sleep(200);
                if (config.verbose) {
                    console.log(outputs);
                }
                if (feed["use_cache_branch"] !== undefined) {
                    copy_kv_caches(feed, outputs)
                    if (config.gen != "llm-decoder" || config.seqlen == 1) {
                        // this is a bit tricky - for some models like gpt2 use of the caches assumes
                        // we pass seqlen=1. So if seqlen=1 set use_cache_branch=1, else don't use the cache.
                        // For models like t5 we can use the cache in all cases.
                        log(`using use_cache_branch, setting to 1`);
                        feed['use_cache_branch'] = new ort.Tensor("bool", [true], [1]);
                    }
                }
                for (var i = 0; i < 4; i++) {
                    outputs = await sess.run(clone(feed));
                    if (config.io_binding) {
                        copy_kv_caches(feed, outputs);
                    }
                }
            }

            log("running...");
            progress.parentNode.style.display = "block";
            await sleep(100);
            const end_time = performance.now() + config.min_query_time;
            let query_count = 0;
            let now;
            let pct_last = 0;

            do {
                const start = performance.now();
                const outputs = await sess.run(clone(feed));
                now = performance.now();
                durations.push(now - start);
                if (config.io_binding) {
                    copy_kv_caches(feed, outputs);
                }
                query_count++;
                const pct_new = Math.min((100 * query_count) / config.min_query_count, (100 - (100 * (end_time - now)) / config.min_query_time));
                if (pct_last + 10 < pct_new) {
                    pct_last = pct_new;
                    progress.style.width = pct_new.toFixed(1) + "%";
                    progress.textContent = progress.style.width;
                    await sleep(50);
                }
            } while (now < end_time || query_count < config.min_query_count);
            const r = logPercentiles(config, durations);
            r.fist_run = fist_run.toFixed(2);
            r.load = load.toFixed(2);
            r.platform = ""
            if (config.csv) {
                r.tag = "@@2";
                const csv = rows.map((x) => { return r[x]; }).join(",");
                console.log(csv);
            }
            const result = `${r.name}/${r.provider}/${r.threads} avg: ${r.avg}, min: ${r.min}, max: ${r.max}, p50: ${r.p50}, p95: ${r.p95}, p99: ${r.p99}, count=${r.count}`;
            log(result + " @@1");
            document.getElementById('results').innerText += result + "\n";
            sess.release();
        } catch (e) {
            log(`${config.name} ${e} @@1`);
            console.log(e);
            if (config.csv) {
                log(`${config.name},${config.provider},${config.threads},0,,,,,,,,,,${e.message.replace("\n", " ")} @@2`);
            }
            if (config.profiler) {
                await sess.endProfiling();
            }
        }
        if (config.download) {
            create_download_link(cons_out);
        }
        progress.parentNode.style.display = "none";
        progress.style.width = "0%";
    }

    if (config.go) {
        bench();
    }
</script>

</html>
